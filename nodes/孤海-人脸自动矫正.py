import cv2
import numpy as np
import torch
import dlib
import os
from math import atan2, degrees

class å­¤æµ·äººè„¸è‡ªåŠ¨çŸ«æ­£:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "å›¾åƒ": ("IMAGE",),
                "å¼€å¯äººè„¸è‡ªåŠ¨çŸ«æ­£": ("BOOLEAN", {"default": True}),
                "è¾¹ç¼˜è£å‰ª": ("INT", {"default": 2, "min": 1, "max": 5, "step": 1}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("çŸ«æ­£åçš„å›¾åƒ",)
    FUNCTION = "process_image"
    CATEGORY = "å­¤æµ·å·¥å…·ç®±"

    def å®Œå…¨æ—‹è½¬(self, img, angle):
        """æ‰§è¡Œå®Œæ•´å›¾åƒæ—‹è½¬ï¼ˆä¸è£å‰ªä¸å¡«å……ï¼‰"""
        if angle == 90:
            return cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)
        elif angle == 270:
            return cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)
        elif angle == 180:
            return cv2.rotate(img, cv2.ROTATE_180)
        return img.copy()

    def å¤šè§’åº¦æ£€æµ‹(self, img):
        """æ”¹è¿›çš„å¤šè§’åº¦æ£€æµ‹ï¼ˆä¿æŒå®Œæ•´å›¾åƒï¼‰"""
        for angle in [0, 90, 180, 270]:
            rotated = self.å®Œå…¨æ—‹è½¬(img, angle)
            gray = cv2.cvtColor(rotated, cv2.COLOR_BGR2GRAY)
            faces = self.äººè„¸æ£€æµ‹å™¨(gray, 0)
            if len(faces) > 0:
                return rotated, angle
        return img, 0

    def process_image(self, **kwargs):
        å›¾åƒ = kwargs["å›¾åƒ"]
        å¼€å¯çŸ«æ­£ = kwargs["å¼€å¯äººè„¸è‡ªåŠ¨çŸ«æ­£"]
        è£å‰ªç³»æ•° = kwargs["è¾¹ç¼˜è£å‰ª"]

        # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ä¸Šçº§ç›®å½•
        current_dir = os.path.dirname(os.path.abspath(__file__))
        parent_dir = os.path.dirname(current_dir)
        model_path = os.path.join(parent_dir, "shape_predictor_5_face_landmarks.dat")
        if not os.path.exists(model_path):
            return (å›¾åƒ, )

        self.äººè„¸æ£€æµ‹å™¨ = dlib.get_frontal_face_detector()
        å…³é”®ç‚¹æ£€æµ‹å™¨ = dlib.shape_predictor(model_path)

        output_images = []
        for img_tensor in å›¾åƒ:
            try:
                if not å¼€å¯çŸ«æ­£:
                    output_images.append(img_tensor)
                    continue

                orig_img = (img_tensor.numpy() * 255).astype(np.uint8)
                orig_img = cv2.cvtColor(orig_img, cv2.COLOR_RGB2BGR)
                
                # ç¬¬ä¸€æ¬¡å®Œæ•´æ—‹è½¬æ£€æµ‹
                rotated_img, pre_angle = self.å¤šè§’åº¦æ£€æµ‹(orig_img)
                current_img = rotated_img.copy()

                # è®¡ç®—ç›®æ ‡å®½é«˜æ¯”
                orig_h, orig_w = orig_img.shape[:2]
                if pre_angle in [90, 270]:
                    target_w, target_h = orig_h, orig_w
                else:
                    target_w, target_h = orig_w, orig_h

                # è§’åº¦çŸ«æ­£å¤„ç†
                gray = cv2.cvtColor(current_img, cv2.COLOR_BGR2GRAY)
                faces = self.äººè„¸æ£€æµ‹å™¨(gray, 0)
                a = 0  # åˆå§‹åŒ–è£å‰ªè§’åº¦
                if faces:
                    æœ€å¤§äººè„¸ = max(faces, key=lambda rect: rect.width() * rect.height())
                    å…³é”®ç‚¹ = å…³é”®ç‚¹æ£€æµ‹å™¨(current_img, æœ€å¤§äººè„¸)

                    # è®¡ç®—çœ¼éƒ¨è§’åº¦
                    å·¦çœ¼ = np.mean([(å…³é”®ç‚¹.part(i).x, å…³é”®ç‚¹.part(i).y) for i in [2,3]], axis=0)
                    å³çœ¼ = np.mean([(å…³é”®ç‚¹.part(i).x, å…³é”®ç‚¹.part(i).y) for i in [0,1]], axis=0)
                    dy = å³çœ¼[1] - å·¦çœ¼[1]
                    dx = å³çœ¼[0] - å·¦çœ¼[0]
                    eye_angle = degrees(atan2(dy, dx))

                    # è§’åº¦ä¿®æ­£é€»è¾‘
                    if eye_angle > 45:
                        eye_angle -= 90
                    elif eye_angle < -45:
                        eye_angle += 90

                    # æ‰§è¡Œæ—‹è½¬
                    (h, w) = current_img.shape[:2]
                    M = cv2.getRotationMatrix2D((w//2, h//2), eye_angle, 1)
                    current_img = cv2.warpAffine(
                        current_img, M, (w, h),
                        flags=cv2.INTER_LANCZOS4,
                        borderMode=cv2.BORDER_REPLICATE
                    )

                    # è®¡ç®—è£å‰ªè§’åº¦a
                    a_abs = abs(eye_angle)
                    a_abs = a_abs % 90
                    if a_abs > 45:
                        a_abs = 90 - a_abs
                    a = a_abs

                # ä¸­å¿ƒè£å‰ª
                final_h, final_w = current_img.shape[:2]
                y_start = max(0, (final_h - target_h) // 2)
                x_start = max(0, (final_w - target_w) // 2)
                final_img = current_img[y_start:y_start+target_h, x_start:x_start+target_w]

                # æ ¹æ®è§’åº¦aè¿›è¡Œè¾¹ç¼˜è£å‰ª
                if a > 0:
                    h_crop, w_crop = final_img.shape[:2]
                    crop_v = max(0, int(h_crop * (a ** 0.8) / 100 / è£å‰ªç³»æ•°))
                    crop_h = max(0, int(w_crop * (a ** 0.8) / 100 / è£å‰ªç³»æ•°))
                    
                    # è®¡ç®—è£åˆ‡åå°ºå¯¸
                    new_h = h_crop - 2 * crop_v
                    new_w = w_crop - 2 * crop_h
                    
                    if new_h > 0 and new_w > 0:
                        final_img = final_img[crop_v:crop_v+new_h, crop_h:crop_h+new_w]

                # è½¬æ¢å›RGB
                final_image = cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB)
                final_image = torch.from_numpy(final_image.astype(np.float32) / 255.0)
                output_images.append(final_image)
            except Exception as e:
                output_images.append(img_tensor)

        return (torch.stack(output_images), )

NODE_CLASS_MAPPINGS = {"å­¤æµ·-äººè„¸è‡ªåŠ¨çŸ«æ­£": å­¤æµ·äººè„¸è‡ªåŠ¨çŸ«æ­£}
NODE_DISPLAY_NAME_MAPPINGS = {"å­¤æµ·-äººè„¸è‡ªåŠ¨çŸ«æ­£": "ğŸ‘¤ å­¤æµ·-äººè„¸è‡ªåŠ¨çŸ«æ­£"}